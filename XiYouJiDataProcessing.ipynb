{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18390831",
   "metadata": {},
   "source": [
    "# 第一步 将初始txt文件按章节切割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e27cfac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "　　《见春天》作者：纵虎嗅花\n",
      "　　文案：\n",
      "　　十五岁的那个夏天，江渡第一次遇见魏清越时，他被一群小混混堵在巷子里暴打，最后，两人一起进了局子。\n",
      "　　后来，江渡才知道，打魏清越最凶的那个，是他的亲爸。\n",
      "　　孤独的少女，爱上孤独的少年，自然而然，成为那个夏天最隐蔽的秘密。\n",
      "　　“而今，在梅中，我遇到的那个人，终会长大，我跟他的所有，皆成文字，北国正芳春。”\n",
      "　　内容标签： 情有独钟 天之骄子 时尚流行\n",
      "　　搜索关键字：主角：江渡，魏清越 ┃ 配角： ┃ 其它：\n",
      "　　一句话简介：爱你就像期待春天\n",
      "　　立意：好好生活\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def split_raw_by_chapter(txt_path:str): #将小说内容按章节进行分割 \n",
    "    with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "        raw_text = f.read()\n",
    "    # chapters = re.split(r'(?=第[一二三四五六七八九十百千〇零\\d]+[章篇回卷部编]\\s+[^ \\n]{2,})', raw_text) #按章节进行分割\n",
    "    chapters = re.split(r'(?=(?:第[一二三四五六七八九十百千〇零\\d]+[章篇回卷部编]\\s+[^ \\n]{2,})|(?:卷[一二三四五六七八九十百千〇零\\d]+\\s*[^ \\n]{2,})|(?:篇[一二三四五六七八九十百千〇零\\d]+\\s*[^ \\n]{2,}))', raw_text) #按章节进行分割\n",
    "    return chapters\n",
    "chapters = split_raw_by_chapter('jianchuntiantest.txt')\n",
    "print(chapters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a9573822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def spilt_chapters_by_amount(chapters:list,file_save_path:str): #对每个章节按500字数的标准进行分割，但是会保留完整句子，不是直接切割。\n",
    "    chunks = []\n",
    "    for chapter in chapters:\n",
    "        chunk = \"\"\n",
    "        sentences = re.split(r'(?<=[。！？”])\\s*', chapter) #将每章内容按句子结束标准进行分割 \n",
    "        for s in sentences:  #将每句话组合在一起，限制为500字\n",
    "            if len(chunk) + len(s) < 500:\n",
    "                chunk += s\n",
    "            else:\n",
    "                chunks.append(chunk)\n",
    "                chunk = s\n",
    "        if chunk: #加入最后一个chunk\n",
    "            chunks.append(chunk)\n",
    "    with open(file_save_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(chunks, f, ensure_ascii=False, indent=2)\n",
    "spilt_chapters_by_amount(chapters,'output_text_data/dirty_chunks_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bf988922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1章 楔子 中考结束后的那个夏天，雨很…… 中考结束后的那个夏天，雨很少，天是那种安静的白热，没有火焰地燃烧着。江渡在这个夏天，进了回局子。那时，她离十五岁生日还差一个月。事情起因简单，当时，她抄近道骑单车回家，在小巷子里看到一群男生打架，严格说，是一个高高的男生被围攻。江渡立刻想起很小的时候，在外公的老家，见过那种一群土狗撕咬一只的情形。男生飞起那么一脚，非常狠，后面有人妄图偷袭，被他手肘重重撞了回去，倒地□□。不过一群人怎么着还是渐渐了上风，江渡脸色发白地看着其中一人拎半块砖头朝他脑袋砸下去，他偏了下头，砖头擦着额角，血这样红，江渡不知道哪里来的勇气，大喊了一句：“警察叔叔来了！”如果说，故事必须有个开头，那么，不是天上那朵怒放的云，也不是谁家电风扇在轰隆隆地转，大街上汽车各有各的目的地，一切一切的开始，不过就是这句“警察叔叔来了”。糟糕的是，这句谎话只是让打架的男生稍微愣了一下，江渡不清楚人家怎么发现她撒谎的，这件破事，反倒把她牵扯过去，她发箍被打掉，车前篮子瘪了，吓得她连哭声都跟平时不一样。后来，警察真的来了，所有人都被带走。\n"
     ]
    }
   ],
   "source": [
    "def data_cleaning(dirty_data_path:str,file_save_path:str): #数据清理\n",
    "    with open(dirty_data_path, 'r', encoding='utf-8') as f:\n",
    "        dirty_data = json.load(f)\n",
    "    cleaned_chunks = [re.sub(r'\\[\\d+\\]', '', chunk) for chunk in dirty_data] #将‘[1]’这样的注脚去除\n",
    "    cleaned_chunks = [re.sub(r'\\s+', ' ', chunk).strip() for chunk in cleaned_chunks] #去除多于的空格、换行符等等\n",
    "    print(cleaned_chunks[1])\n",
    "    with open(file_save_path,'w',encoding='utf-8') as f:\n",
    "        json.dump(cleaned_chunks, f, ensure_ascii=False, indent=2)\n",
    "data_cleaning('output_text_data/dirty_chunks_data.json','output_text_data/cleaned_chunks_data.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastApi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
